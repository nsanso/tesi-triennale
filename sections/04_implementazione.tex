\chapter{Architettura e implementazione}
\label{sec:implementazione}

% TODO: AGGIUNGI IMMAGINI, RIFERIMENTI 

% Definire e desccrivere nei dettagli l'architettura a blocchi, descrivendo ciascun blocco e i collegamenti.
% Non è ancora necessario dare dettagli implementativi, che andranno nel capitolo dedicato.
% Descrizione tecnologie utilizzate per implementare ciascun blocco.
% Qui vanno i dettagli implementativi per ciascun blocco dell'architettura definita nel capitolo precedente.
% Potrebbe convenire replicare l'immagine dell'architettura, definendo all'interno dell'immagine dettagli implementativi come ad esempio i nomi dei moduli utilizzati e le tecnologie utilizzate per implementarli.

\section{Sistema di rilevazione anomalie}
Il sistema di rilevazione anomalie, in cui il modulo di correzione è implementato, è costituito dai moduli in figura \ref{fig:sys modules}.
\begin{figure}
    \caption{Architettura del sistema di rilevazione anomalie}
    \label{fig:sys modules}
    \centering
    \includegraphics[width=.66\textwidth]{images/placeholder.png}
\end{figure}
Il sistema è implementato sul dispositivo \emph{NVidia Jetson Xaxier} ed è sviluppato su \emph{Ubuntu 18.04}.
Il linguaggio di sviluppo è \emph{Python 3.6}.
Per la gestione delle operazione di algebra lineare sono stati utilizzati i package \emph{Numpy} e \emph{SciPy}.
La pipeline di acquisizione è gestita dalla libreria \emph{GStreamer}.
La classificazione è effettuata dal modulo di inferenza fornito dall'\emph{SDK NVidia Deepstream}.
Questo modulo di inferenza è configurato per il modello di \emph{Object Detection YoloV4}.

Il modulo di correzione si occupa della rimozione di duplicati ed occlusioni e della correzione della distorsione prospettica descritta in questa tesi.

Il modulo di tracking effettua il tracciamento delle entità, utilizzando una funzione di smoothing per ridurre le imprecisioni della classificazione.
Il tracking è effettuato sia utilizzando l'ultima posizione conosciuta, sia la posizione predetta in base a velocità e accelerazione.

Il modulo di rilevazione di anomalie si occupa di posizionare le entità all'interno della mappa stradale (preconfigurata da un operatore), di assegnarvi una forma approssimata e di comunicare con i sottomoduli di rilevazione delle singole anomalie.

I dati relativi alla mappa sono gestiti attraverso coordinate baricentriche e sono utilizzati per \emph{Cambio di corsia}, \emph{Sosta vietata}, \emph{Persona in strada}, \emph{Invasione di area}.

Gli \emph{Urti} sono verificati simulando la posizione futura delle entità e cercando intersezioni con l'algoritmo \emph{GJK}.

Il modulo di comunicazione ottiene i dati relativi alle anomalie e lo stream video e si occupa di salvare segmenti di video in cui sono presenti una o più anomalie.
I dati relativi alle anomalie e il percorso del video sono inviati tramite richiesta HTTP al \emph{Microservizio}, implementato nello stesso dispositivo, che gestisce la comunicazione col backend principale.
Il modulo di comunicazione utilizza \emph{OpenCV} per il salvataggio del video e \emph{Requests} per la comunicazione HTTP.

Il \emph{Microservizio} è implementato con \emph{NodeJS}, \emph{Express}, \emph{Sequelize} e utilizza un database \emph{MariaDB}.

\section{Strumento interattivo}
Lo strumento interattivo è scritto in \emph{TypeScript} e utilizza il framework \emph{SvelteKit}.
Per le operazioni di algebra lineare è utilizzato \emph{MathJS}.
Per implementare il rendering dell'immagine manipolata è stato utilizzato \emph{GpuJS}, in quanto ha consentito di evitare i costi di tempo richiesti per imparare \emph{WebGL}.
Questa libreria non è però abbastanza matura e presenta alcuni comportamenti non ideali, ed è quindi raccomandabile spendere il tempo necessario per imparare \emph{WebGL} in futuro.
Tutto il resto delle funzioni è implementato attraverso l'uso di \emph{WebAPI} e \emph{Svelte}.
Il deploy è effettuato come \emph{SPA} su \emph{GitHub Pages}.
